{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import dependencies\n",
    "\n",
    "To install:\n",
    "\n",
    "`pip install 'git+https://github.com/DLR-RM/stable-baselines3#egg=stable-baselines3[extra]'`\n",
    "\n",
    "The version on PyPI is currently broken, installing directly from GitHub fixes this.\n",
    "\n",
    "You may also want to install PyTorch for CUDA, if available:\n",
    "\n",
    "[PyTorch Install Guide](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment\n",
    "\n",
    "[CartPole](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with score 20.0\n",
      "Episode 2 finished with score 15.0\n",
      "Episode 3 finished with score 11.0\n",
      "Episode 4 finished with score 14.0\n",
      "Episode 5 finished with score 11.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f'Episode {episode+1} finished with score {score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Spaces\n",
    "\n",
    "[Wiki](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html)\n",
    "\n",
    "![RL Algorithm Comparison](./RL_Alg_Comparison.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I got a big long error due to having CUDA 11.4 and PyTorch for CUDA 11.3. I downgraded to CUDA 11.3 using [this guide](https://denishartl.com/installing-cuda-11-3-cudnn-tensorflow-2-4-jupyter-on-a-headless-ubuntu-20-04-server/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1271 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 940          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074686827 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.688       |\n",
      "|    explained_variance   | -0.00524     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.17         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    value_loss           | 52.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 831        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01014233 |\n",
      "|    clip_fraction        | 0.0629     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.668     |\n",
      "|    explained_variance   | 0.108      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 33.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 774         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009329958 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 765         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006212755 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 762         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007891433 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 761          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069867363 |\n",
      "|    clip_fraction        | 0.0753       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.607       |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 768         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006255068 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 768          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078118034 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 765          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063992646 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 762          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056419256 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 762          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048301974 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.537        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 7.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 761          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019097177 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 759          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060391803 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | -0.0983      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.298        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 3.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 759          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073318416 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 6.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 760         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009841983 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 759         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007904299 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.555      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 0.919       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 760         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006659217 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | -0.0989     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.000447   |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 755          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017531528 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0135       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0788       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -2.62e-05    |\n",
      "|    value_loss           | 0.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073568877 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0223       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 0.263        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 748          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032307832 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.00766      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0432       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 0.161        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034448085 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0538       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 746         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005920452 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.0432      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    value_loss           | 0.0725      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 747         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005737205 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | -0.0128     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 0.0457      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 747          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062889103 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | -0.00963     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0172       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 0.0313       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 748          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032336414 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00957      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 0.0219       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 748          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029011862 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.000625     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0174       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000995    |\n",
      "|    value_loss           | 0.0152       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016072745 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.023        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000782    |\n",
      "|    value_loss           | 0.0102       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051350626 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0456       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00875      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 0.00712      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034549823 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0143       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000665    |\n",
      "|    value_loss           | 0.00484      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041803336 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | -0.0429      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00432     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 0.00362      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 750        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 87         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00619122 |\n",
      "|    clip_fraction        | 0.0398     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.515     |\n",
      "|    explained_variance   | -0.0613    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00667    |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00265   |\n",
      "|    value_loss           | 0.00243    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005414609 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | -0.0948     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0158      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.000837   |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026339605 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | -0.0638      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00212      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00091     |\n",
      "|    value_loss           | 0.00123      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037831897 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | -0.0171      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00245      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 0.000908     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 748          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021679811 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | -0.0844      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00357     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000775    |\n",
      "|    value_loss           | 0.000613     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031867109 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | -0.06        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00253      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 0.000429     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 744          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050398475 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | -0.0522      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00758     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 0.000318     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 742          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041814703 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | -0.013       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0175       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 0.000255     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 740          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061114607 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | -0.0608      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0126       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 0.000171     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 739          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043222057 |\n",
      "|    clip_fraction        | 0.0624       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | -0.153       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0222      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 0.000124     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026018862 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | -0.0993      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0148       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 9.63e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022971067 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | -0.121       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.014        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    value_loss           | 6.84e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 734          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051969704 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | -0.118       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00546     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 4.86e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027570543 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | -0.195       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00911      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 4.22e-05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 729        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00487944 |\n",
      "|    clip_fraction        | 0.0354     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.443     |\n",
      "|    explained_variance   | -0.207     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00883    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    value_loss           | 2.86e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 727          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041785697 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | -0.222       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00379      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000889    |\n",
      "|    value_loss           | 1.9e-05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003443492 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | -0.204      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00028    |\n",
      "|    value_loss           | 1.93e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 724           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074158463 |\n",
      "|    clip_fraction        | 0.0255        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.432        |\n",
      "|    explained_variance   | -0.525        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00355       |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000359     |\n",
      "|    value_loss           | 1.85e-05      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f9ef57957b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved_Models', 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/stark/Documents/WSU/Data-Analysis/OpenAI-Gym/Experiments/Reinforcement_Learning/Tutorial/Reinforcement_Learning.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stark/Documents/WSU/Data-Analysis/OpenAI-Gym/Experiments/Reinforcement_Learning/Tutorial/Reinforcement_Learning.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m model\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stark/Documents/WSU/Data-Analysis/OpenAI-Gym/Experiments/Reinforcement_Learning/Tutorial/Reinforcement_Learning.ipynb#ch0000015?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m PPO\u001b[39m.\u001b[39mload(PPO_Path, env\u001b[39m=\u001b[39menv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with score 200.0\n",
      "Episode 2 finished with score 200.0\n",
      "Episode 3 finished with score 200.0\n",
      "Episode 4 finished with score 200.0\n",
      "Episode 5 finished with score 200.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f'Episode {episode+1} finished with score {score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render for nice pretty video\n",
    "from time import time\n",
    "obs = env.reset()\n",
    "\n",
    "t_start = time()\n",
    "while time() - t_start < 60:\n",
    "    env.render()\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _, _ = env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Viewing Logs in Tensorboard\n",
    "Run this in a shell so you don't lock up your notebook.\n",
    "\n",
    "If Tensorflow not installed, follow [this](https://www.tensorflow.org/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-23 18:12:21.298294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 18:12:21.302389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 18:12:21.302757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.8.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_2')\n",
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Adding a Callback to the Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved_Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
    "eval_callback = EvalCallback(env,\n",
    "                             callback_on_new_best=stop_callback,\n",
    "                             eval_freq=10000,\n",
    "                             best_model_save_path=save_path,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = [dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba535a1ceb8d036bf4aa57205ad58728f466c1d392a325537ed761910cbd4e23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
